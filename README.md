## Amazon Rekognition Engagement Meter

The Engagement Meter calculates and shows engagement levels of an audience participating to a meeting. It also allows the user to add people by associating names with photos, in order for them to be recognized when participating to the meeting.

It could also be a useful playground to learn about Amazon Rekognition and other AWS services.

### Usage

The demo is available as [AWS CloudFormation](https://aws.amazon.com/cloudformation) template.
[Download the template](https://s3-eu-west-1.amazonaws.com/rekognition-engagement-meter/template.yaml) or [Deploy using the AWS Console](https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=EngagementMeter&templateURL=https://s3-eu-west-1.amazonaws.com/rekognition-engagement-meter/template.yaml).

Note: when picking an AWS Region, ensure Amazon Rekognition Image is available in that region ([Amazon Rekognition FAQ](https://aws.amazon.com/rekognition/faqs/)).

### Architecture

The engagement meter uses [Amazon Rekognition](https://aws.amazon.com/rekognition) for image and sentiment analysis, [Amazon DynamoDB](https://aws.amazon.com/dynamodb) for storage, [Amazon API Gateway](https://aws.amazon.com/api-gateway) and [Amazon Cognito](https://aws.amazon.com/cognito) for the API, and [Amazon S3](https://aws.amazon.com/s3), [AWS Amplify](https://aws.amazon.com/amplify) and [React](https://reactjs.org) for the front-end layer.

<img src="docs/amazon-rekognition-1.png" alt="Architecture Diagram" />

### User flow


There are three main user flows: the **"add user"** flow (*yellow*) is triggered when clicking the "Add user" button; the **"added users recognition"** flow (*green*) and the **"sentiment analysis"** flow (*blue*) are triggered when clicking the "Start Rekognition" button and cyclically repeat until the "Stop Rekognition" button is clicked.

In the diagram below are represented the API calls performed by Amplify (which takes care of authenticating all the calls to the API Gateway using Cognito).

<img src="docs/amazon-rekognition-2.png" alt="User flow" />

The **"add user"** flow (*yellow*) consists on a `POST /faces/add` call to the API gateway containing the user's uploaded image and an autogenerated unique identifier, (known as `ExternalImageId`) when calling the `IndexFaces` action in Amazon Rekognition. Then, a `POST /people` is performed to the API gateway to associate the ExternalImageId to some extra metadata (Name and JobTitle) to the Faces Table in Amazon DynamoDB. To learn more about IndexFaces click [here](https://docs.aws.amazon.com/rekognition/latest/dg/API_IndexFaces.html).

The **"added users recognition"** flow (green) starts with a `POST /people` to query the Faces Table on Amazon DynamoDB. In case any people have been registered, another call to `POST /faces/search` is performed including a screenshot detected from the webcam. That photo will be sent to Amazon Rekognition as a `SearchFacesByImage` action: if any previously registered person will be recognised, the service will provide details about the face matches, including each face's coordinate and confidence. In this case, the UI will show a welcome message showing the recognized users' names. To learn more about SearchFacesByImage click [here](https://docs.aws.amazon.com/rekognition/latest/dg/API_SearchFacesByImage.html).

The **"sentiment analysis"** flow (blue) consists on two parallel calls to the API gateway (here represented in a sequential manner for simplicity). First there is a call to `POST /faces/detect` with a screenshot detected from the webcam, which then calls the `DetectedFaces` action on Amazon Rekognition. If any face will be detected, the information will provide information about the matched people, including physical caracteristics and sentiments. In that case, a little recap will be shown on the UI for each recognized person and another call to `POST /engagement` will be performed with some of the recognized sentiments (Angry, Confused, Happy, Sad, Surprised) to be saved to the Sentiment table in DynamoDB. In parallel, a `GET /engagement` call then queries the same DynamoDB table for all the sentiments recorded during the last hour, in order to calibrate and draw the meter. To learn more about DetectFaces click [here](https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html).

## Contributing

Contributions are more than welcome. Please read the [code of conduct](CODE_OF_CONDUCT.md) and the [contributing guidelines](CONTRIBUTING.md).

## License Summary

This sample code is made available under a modified MIT license. See the LICENSE file.
